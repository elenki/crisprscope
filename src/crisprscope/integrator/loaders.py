"""
CRISPRScope: Data loading functions for the Integrator module.

This module contains functions to parse and load the various output and
configuration files generated by the CRISPRScope orchestrator and CRISPResso2.
"""

import pandas as pd
from pathlib import Path
from typing import Dict, Any, List
import gzip
import os
import traceback
from collections import Counter
from multiprocessing import Pool, cpu_count
import logging

logger = logging.getLogger(__name__)

# --- Helper function for parallel processing ---

def _parse_single_fastq_file(file_path: Path) -> List[Dict[str, Any]]:
    """
    Parses a single CRISPResso_output.fastq.gz file to count alleles.
    This function is designed to be called by a multiprocessing worker.
    """
    amplicon_name = file_path.parent.name[len("CRISPResso_on_"):]
    
    # Using Counter is more efficient for this task than defaultdict
    allele_counts = Counter()
    
    try:
        with gzip.open(file_path, 'rt') as f:
            # An iterator-based approach is cleaner and safer
            for header in f:
                sequence = next(f).strip()
                next(f) # Skip '+'
                next(f) # Skip quality

                # Header format assumed: @{read_id}:{cell_barcode}:{amplicon_id}
                # This is a fragile assumption, but we conform to the spec for now.
                cell_barcode = header.strip().split(':')[-2]
                allele_counts[(cell_barcode, sequence)] += 1
                
    except StopIteration:
        logger.warning(f"File {file_path} appears to be truncated or empty.")
    except Exception as e:
        logger.error(f"Error parsing file {file_path}: {e}\n{traceback.format_exc()}")
        return [] # Return empty list on error

    # Convert the Counter object to the structured list format
    results = [
        {
            'cell_barcode': cell_barcode,
            'amplicon_name': amplicon_name,
            'allele_sequence': sequence,
            'count': count
        }
        for (cell_barcode, sequence), count in allele_counts.items()
    ]
    
    return results

# --- Main Loader Functions ---

def load_settings(settings_path: Path) -> Dict[str, Any]:
    """Parses the settings.txt configuration file."""
    if not settings_path.is_file():
        logger.error(f"Settings file not found at: {settings_path}")
        raise FileNotFoundError(f"Settings file not found: {settings_path}")
    logger.info(f"Parsing settings from: {settings_path}")
    settings = {}
    with open(settings_path, 'r') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            parts = line.split(None, 1)
            if len(parts) == 2:
                key, value = parts
                settings[key] = value
            else:
                logger.warning(f"Could not parse line in settings file: '{line}'")
    logger.info(f"Successfully loaded {len(settings)} parameters from settings file.")
    return settings

def load_amplicons(amplicons_path: Path) -> pd.DataFrame:
    """Parses the amplicons.txt file into a DataFrame."""
    if not amplicons_path.is_file():
        logger.error(f"Amplicons file not found at: {amplicons_path}")
        raise FileNotFoundError(f"Amplicons file not found: {amplicons_path}")
    logger.info(f"Parsing amplicons from: {amplicons_path}")
    try:
        df = pd.read_csv(amplicons_path, sep='\t', header=None, index_col=0, names=['sequence', 'guide'])
        df.index.name = 'amplicon_name'
        logger.info(f"Successfully loaded {len(df)} amplicons.")
        return df
    except Exception as e:
        logger.error(f"Failed to parse amplicons file: {e}")
        raise

def load_editing_summary(summary_path: Path) -> pd.DataFrame:
    """Loads the main data matrix from settings.txt.filteredEditingSummary.txt."""
    if not summary_path.is_file():
        logger.error(f"Editing summary file not found at: {summary_path}")
        raise FileNotFoundError(f"Editing summary file not found: {summary_path}")
    logger.info(f"Parsing editing summary from: {summary_path}")
    try:
        df = pd.read_csv(summary_path, sep='\t', index_col=0)
        df.index.name = 'cell_barcode'
        logger.info(f"Successfully loaded editing data for {df.shape[0]} cells and {df.shape[1]} metrics.")
        return df
    except Exception as e:
        logger.error(f"Failed to parse editing summary file: {e}")
        raise

def load_quality_scores(scores_path: Path) -> pd.DataFrame:
    """Loads the cell quality metrics from settings.txt.amplicon_score.txt."""
    if not scores_path.is_file():
        logger.error(f"Amplicon scores file not found at: {scores_path}")
        raise FileNotFoundError(f"Amplicon scores file not found: {scores_path}")
    logger.info(f"Parsing quality scores from: {scores_path}")
    try:
        df = pd.read_csv(scores_path, sep='\t', index_col=0)
        df.index.name = 'cell_barcode'
        logger.info(f"Successfully loaded quality scores for {len(df)} cells.")
        return df
    except Exception as e:
        logger.error(f"Failed to parse quality scores file: {e}")
        raise

def load_crispresso_alleles(crispresso_dir: Path, n_processes: int = None) -> pd.DataFrame:
    """
    Loads allele information from the CRISPResso2 filtered output directory
    using parallel processing and returns a single, structured DataFrame.

    Args:
        crispresso_dir: Path to the 'settings.txt.crispresso.filtered' directory.
        n_processes: Number of parallel processes to use. Defaults to all available CPUs.

    Returns:
        A pandas DataFrame with columns: ['cell_barcode', 'amplicon_name', 
                                         'allele_sequence', 'count'].
    """
    if not crispresso_dir.is_dir():
        logger.error(f"CRISPResso output directory not found at: {crispresso_dir}")
        raise FileNotFoundError(f"Directory not found: {crispresso_dir}")

    logger.info(f"Scanning for allele data in: {crispresso_dir}")
    
    # 1. Collect all file paths to be processed
    files_to_process = []
    for entry in os.scandir(crispresso_dir):
        if entry.is_dir() and entry.name.startswith("CRISPResso_on_"):
            file_path = Path(entry.path) / "CRISPResso_output.fastq.gz"
            if file_path.is_file():
                files_to_process.append(file_path)
    
    if not files_to_process:
        logger.warning("No CRISPResso FASTQ files found to parse. Returning empty DataFrame.")
        return pd.DataFrame(columns=['cell_barcode', 'amplicon_name', 'allele_sequence', 'count'])

    logger.info(f"Found {len(files_to_process)} amplicon files to parse.")

    # 2. Process files in parallel
    if n_processes is None:
        n_processes = cpu_count()
    logger.info(f"Starting parallel parsing with {n_processes} processes...")
    
    with Pool(processes=n_processes) as pool:
        # map applies the function to each item in the list and returns a list of results
        results_list_of_lists = pool.map(_parse_single_fastq_file, files_to_process)
    
    # 3. Flatten the list of lists into a single list of dictionaries
    logger.info("Parallel processing complete. Consolidating results...")
    all_results = [item for sublist in results_list_of_lists for item in sublist]

    if not all_results:
        logger.warning("Parsing yielded no allele data. Returning empty DataFrame.")
        return pd.DataFrame(columns=['cell_barcode', 'amplicon_name', 'allele_sequence', 'count'])

    # 4. Convert to a DataFrame for clean, structured output
    alleles_df = pd.DataFrame(all_results)
    
    logger.info(f"Successfully created DataFrame with {len(alleles_df)} total allele records.")
    return alleles_df
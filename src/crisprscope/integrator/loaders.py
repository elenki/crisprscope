"""
CRISPRScope: Data loading functions for the Integrator module.

This module contains functions to parse and load the various output and
configuration files generated by the CRISPRScope orchestrator and CRISPResso2.
"""

import pandas as pd
from pathlib import Path
from typing import Dict, Any
import gzip
import os
from collections import defaultdict
import traceback

import logging
logger = logging.getLogger(__name__)

def load_settings(settings_path: Path) -> Dict[str, Any]:
    """Parses the settings.txt configuration file."""
    if not settings_path.is_file():
        logger.error(f"Settings file not found at: {settings_path}")
        raise FileNotFoundError(f"Settings file not found: {settings_path}")
    logger.info(f"Parsing settings from: {settings_path}")
    settings = {}
    with open(settings_path, 'r') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            parts = line.split(None, 1)
            if len(parts) == 2:
                key, value = parts
                settings[key] = value
            else:
                logger.warning(f"Could not parse line in settings file: '{line}'")
    logger.info(f"Successfully loaded {len(settings)} parameters from settings file.")
    return settings

def load_amplicons(amplicons_path: Path) -> pd.DataFrame:
    """Parses the amplicons.txt file into a DataFrame."""
    if not amplicons_path.is_file():
        logger.error(f"Amplicons file not found at: {amplicons_path}")
        raise FileNotFoundError(f"Amplicons file not found: {amplicons_path}")
    logger.info(f"Parsing amplicons from: {amplicons_path}")
    try:
        df = pd.read_csv(amplicons_path, sep='\t', header=None, index_col=0, names=['sequence', 'guide'])
        df.index.name = 'amplicon_name'
        logger.info(f"Successfully loaded {len(df)} amplicons.")
        return df
    except Exception as e:
        logger.error(f"Failed to parse amplicons file: {e}")
        raise

def load_editing_summary(summary_path: Path) -> pd.DataFrame:
    """Loads the main data matrix from settings.txt.filteredEditingSummary.txt."""
    if not summary_path.is_file():
        logger.error(f"Editing summary file not found at: {summary_path}")
        raise FileNotFoundError(f"Editing summary file not found: {summary_path}")
    logger.info(f"Parsing editing summary from: {summary_path}")
    try:
        df = pd.read_csv(summary_path, sep='\t', index_col=0)
        df.index.name = 'cell_barcode'
        logger.info(f"Successfully loaded editing data for {df.shape[0]} cells and {df.shape[1]} metrics.")
        return df
    except Exception as e:
        logger.error(f"Failed to parse editing summary file: {e}")
        raise

def load_quality_scores(scores_path: Path) -> pd.DataFrame:
    """Loads the cell quality metrics from settings.txt.amplicon_score.txt."""
    if not scores_path.is_file():
        logger.error(f"Amplicon scores file not found at: {scores_path}")
        raise FileNotFoundError(f"Amplicon scores file not found: {scores_path}")
    logger.info(f"Parsing quality scores from: {scores_path}")
    try:
        df = pd.read_csv(scores_path, sep='\t', index_col=0)
        df.index.name = 'cell_barcode'
        logger.info(f"Successfully loaded quality scores for {len(df)} cells.")
        return df
    except Exception as e:
        logger.error(f"Failed to parse quality scores file: {e}")
        raise

def load_crispresso_alleles(crispresso_dir: Path) -> Dict[tuple, Dict[str, int]]:
    """
    Loads allele information from the CRISPResso2 filtered output directory.

    This function walks the directory structure, finds all per-amplicon
    CRISPResso_output.fastq.gz files, and parses them to count the occurrences
    of each unique allele sequence for each cell.
    """
    if not crispresso_dir.is_dir():
        logger.error(f"CRISPResso output directory not found at: {crispresso_dir}")
        raise FileNotFoundError(f"Directory not found: {crispresso_dir}")

    logger.info(f"Scanning for allele data in: {crispresso_dir}")
    allele_counts = defaultdict(lambda: defaultdict(int))
    
    # Use os.scandir for a more efficient way to find directories
    for entry in os.scandir(crispresso_dir):
        if entry.is_dir() and entry.name.startswith("CRISPResso_on_"):
            
            # Strip the prefix to get the canonical amplicon name
            amplicon_name = entry.name[len("CRISPResso_on_"):]
            
            file_path = Path(entry.path) / "CRISPResso_output.fastq.gz"
            
            if not file_path.is_file():
                continue

            logger.info(f"  - Parsing alleles for amplicon '{amplicon_name}' from {file_path}")
            
            try:
                with gzip.open(file_path, 'rt') as f:
                    # Use a while loop instead of a for loop to handle empty/truncated files
                    while True:
                        header_line = f.readline()
                        if not header_line:
                            break # End of file
                        
                        seq_line = f.readline()
                        plus_line = f.readline()
                        qual_line = f.readline()

                        # Ensure we have a complete 4-line record
                        if not qual_line:
                            logger.warning(f"Incomplete FASTQ record found at end of {file_path}")
                            break

                        #parsing logic for the header
                        cell_barcode = header_line.strip().split(':')[-2]
                        sequence = seq_line.strip()
                        allele_counts[(cell_barcode, amplicon_name)][sequence] += 1
            
            except Exception:
                logger.warning(f"Could not parse file {file_path}:\n{traceback.format_exc()}")

    logger.info(f"Successfully parsed allele data for {len(allele_counts)} cell-amplicon pairs.")
    return dict(allele_counts)